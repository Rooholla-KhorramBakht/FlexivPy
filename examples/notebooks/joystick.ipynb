{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from FlexivPy.joy import XBoxController\n",
    "joy = XBoxController(0)\n",
    "joy.getStates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going through the next cells, start the asynchronous simulator or the real robot bridge by tunning the following in your terminal:\n",
    "\n",
    "**Asynchronous Simulator:**\n",
    "\n",
    "```bash\n",
    "flexivpy_async_sim --mode velocity\n",
    "```\n",
    "\n",
    "**Real Robot Client**\n",
    "\n",
    "```bash\n",
    "robot_server -cm 3 -g --path /home/FlexivPy/FlexivPy/assets/ -rcf /home/FlexivPy/flexivpy_bridge/config.yaml\n",
    "```\n",
    "The `cm` 3 means that the robot is started in joint velocity mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinocchio as pin\n",
    "import numpy as np\n",
    "from FlexivPy.robot.model.pinocchio import FlexivModel\n",
    "from FlexivPy.robot.interface import FlexivDDSClient\n",
    "import time\n",
    "from FlexivPy.robot.dds.subscriber import get_last_msg\n",
    "import cv2\n",
    "from cyclonedds.domain import DomainParticipant\n",
    "from cyclonedds.topic import Topic\n",
    "from cyclonedds.sub import Subscriber, DataReader\n",
    "import time\n",
    "\n",
    "from cyclonedds.domain import DomainParticipant\n",
    "from cyclonedds.topic import Topic\n",
    "from FlexivPy.robot.dds.flexiv_messages import EnvImage\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CameraDDSClient:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.domain_participant = DomainParticipant(10)\n",
    "\n",
    "        self.topic_env_image = Topic(self.domain_participant, \"EnvImage\", EnvImage)\n",
    "        self.subscriber_env_image = Subscriber(self.domain_participant)\n",
    "        self.reader_env_image = DataReader(\n",
    "            self.subscriber_env_image, self.topic_env_image\n",
    "        )\n",
    "\n",
    "        self.warning_no_env_image_dt = 0.2\n",
    "        self.warning_no_env_image_send = 0.2\n",
    "\n",
    "        self.max_wait_time_first_msg = 20\n",
    "\n",
    "        \n",
    "\n",
    "        # create a smiluation in another process\n",
    "        self.last_img = None\n",
    "\n",
    "        tic = time.time()\n",
    "       \n",
    "        self.time_last_img = tic\n",
    "\n",
    "        tic = time.time()\n",
    "        print(\"waiting to receive the image ...\")\n",
    "        while True:\n",
    "            if self.is_ready():\n",
    "                print(\"Camera is ready!\")\n",
    "                break\n",
    "            if time.time() - tic > self.max_wait_time_first_msg:\n",
    "                raise Exception(\"Camera is not ready! -- Start the server first!\")\n",
    "            time.sleep(.1)\n",
    "\n",
    "    def is_ready(self):\n",
    "        return self.get_env_image() is not None\n",
    "\n",
    "\n",
    "    def get_env_image(self):\n",
    "        tic = time.time()\n",
    "        msg = get_last_msg(self.reader_env_image, EnvImage)\n",
    "        if msg:\n",
    "            now = datetime.now()  # TODO: avoid calling tic twice\n",
    "            print(now.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-4])\n",
    "            print(\"msg.time\", msg.timestamp)\n",
    "            np_array = np.frombuffer(bytes(msg.data), dtype=np.uint8)\n",
    "            frame = cv2.imdecode(np_array, cv2.IMREAD_COLOR)\n",
    "            self.last_img = frame\n",
    "            self.time_last_img = tic\n",
    "            self.warning_no_env_image_send = False\n",
    "        else:\n",
    "            if (\n",
    "                tic - self.time_last_img > self.warning_no_env_image_dt\n",
    "                and not self.warning_no_env_image_send\n",
    "            ):\n",
    "                print(\n",
    "                    f\"warning: client did not recieve env image in  last {self.warning_no_env_image_dt} [s]\"\n",
    "                )\n",
    "                self.warning_no_env_image_send = True\n",
    "                self.warning_no_env_image_send = False\n",
    "\n",
    "        return self.last_img\n",
    "\n",
    "\n",
    "model = FlexivModel()\n",
    "robot = FlexivDDSClient()\n",
    "# Run this in another terminal!\n",
    "# python FlexivPy/async_camera_app.py\n",
    "\n",
    "camera = CameraDDSClient()\n",
    "image = camera.get_env_image()\n",
    "print(type(image))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the griper.\n",
    "from FlexivPy.controllers.gripper import CloseGripper, OpenGripper\n",
    "from FlexivPy.controllers.runners import NonBlockingRunner, blocking_runner\n",
    "import time\n",
    "\n",
    "controller = CloseGripper(control_mode=\"velocity\")\n",
    "\n",
    "status =  blocking_runner(\n",
    "    robot, \n",
    "    controller, \n",
    "    timeout=10,\n",
    "    callback=None\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlexivPy.controllers.taskspace import DiffIKController\n",
    "\n",
    "\n",
    "def get_T_from_controller(state):\n",
    "    info = model.getInfo(np.array(state.q), np.array(state.dq))\n",
    "    T0 = info[\"poses\"][\"link7\"]\n",
    "    # Initialize the desired pose\n",
    "    x0, y0, z0 = 0.0, 0.0, 0.0\n",
    "    R0 = np.eye(3)\n",
    "\n",
    "    rate = 1.0 / 100.0\n",
    "\n",
    "    joy_state = joy.getStates()\n",
    "    left_joy = joy_state[\"left_joy\"]\n",
    "    right_joy = joy_state[\"right_joy\"]\n",
    "\n",
    "    if joy_state[\"right_bumper\"] == 0:\n",
    "        vx_cmd = right_joy[1]\n",
    "        vy_cmd = right_joy[0]\n",
    "        vz_cmd = left_joy[0]\n",
    "        if np.abs(vx_cmd) < 0.1:\n",
    "            vx_cmd = 0\n",
    "        if np.abs(vy_cmd) < 0.1:\n",
    "            vy_cmd = 0\n",
    "        if np.abs(vz_cmd) < 0.1:\n",
    "            vz_cmd = 0\n",
    "        y0 = y0 + vy_cmd * rate\n",
    "        x0 = x0 + vx_cmd * rate\n",
    "        z0 = z0 - vz_cmd * rate\n",
    "    else:\n",
    "        wx_cmd = right_joy[1]\n",
    "        wy_cmd = right_joy[0]\n",
    "        wz_cmd = left_joy[0]\n",
    "        if np.abs(wx_cmd) < 0.1:\n",
    "            wx_cmd = 0\n",
    "        if np.abs(wy_cmd) < 0.1:\n",
    "            wy_cmd = 0\n",
    "        if np.abs(wz_cmd) < 0.1:\n",
    "            wz_cmd = 0\n",
    "        cmd = np.array([wx_cmd, wy_cmd, wz_cmd])\n",
    "        omega_hat = np.array(\n",
    "            [[0, -cmd[2], cmd[1]], [cmd[2], 0, -cmd[0]], [-cmd[1], cmd[0], 0]]\n",
    "        )\n",
    "        R0 = R0 @ (np.eye(3) + omega_hat / 100)\n",
    "\n",
    "    # time.sleep(0.01)\n",
    "    T_cmd = T0 @ np.vstack(\n",
    "        [np.hstack([R0, np.array([x0, y0, z0]).reshape(3, 1)]), np.array([0, 0, 0, 1])]\n",
    "    )\n",
    "    return T_cmd\n",
    "\n",
    "\n",
    "task_controller = DiffIKController(\n",
    "    model, T_cmd_fun=get_T_from_controller, dt=0.01, dq_max=1.0, control_mode=\"velocity\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class CallbackFun(): \n",
    "    def __init__(self):\n",
    "        self.cmds = []\n",
    "        self.callback_dt = 0.01\n",
    "        self.states = []\n",
    "        self.imgs = []\n",
    "        self.last_callback_t = -1\n",
    "\n",
    "    def __call__(self, robot, cmd , _):\n",
    "        tic = time.time()\n",
    "        if tic - self.last_callback_t > self.callback_dt:\n",
    "            last_callback_t = self.callback_dt\n",
    "            self.cmds.append(cmd)\n",
    "            self.states.append(robot.get_robot_state())\n",
    "            self.imgs.append(camera.get_env_image())\n",
    "\n",
    "callback = CallbackFun()\n",
    "\n",
    "\n",
    "status = blocking_runner(robot, task_controller, timeout=120, callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(callback.imgs))\n",
    "# lets create a video. \n",
    "import imageio\n",
    "import pickle\n",
    "import numpy as np\n",
    "imageio.mimsave(\"tmp.mp4\" , np.stack(callback.imgs) , fps=30, codec = \"h264\")\n",
    "# with open(\"all_data.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(\n",
    "#         {\n",
    "#             \"q\": [ [i for i in x.q ] for x in callback.states ] ,\n",
    "#             \"dq\" :  [ [i for i in x.dq ] for x in callback.states ] ,\n",
    "#             \"imgs\" : callback.imgs\n",
    "#         } , f\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = camera.get_env_image()\n",
    "img = img[::2,::2,:]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_data.pkl\", \"rb\") as f:\n",
    "    D = pickle.load(f)\n",
    "print(D.keys())\n",
    "print(D[\"q\"][0])\n",
    "print(D[\"imgs\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "class QVideoCapture:\n",
    "    def __init__(self, name):\n",
    "        self.cap = cv2.VideoCapture(name)\n",
    "        self.lock = threading.Lock()\n",
    "        self.running = True  # Flag to control the thread\n",
    "        self.t = threading.Thread(target=self._reader)\n",
    "        self.t.start()\n",
    "\n",
    "    # Grab frames as soon as they are available\n",
    "    def _reader(self):\n",
    "        while self.running:\n",
    "            with self.lock:\n",
    "                ret = self.cap.grab()\n",
    "                time.sleep(0.01)\n",
    "                # sleep \n",
    "            if not ret:\n",
    "                # If grabbing fails, perhaps the camera was disconnected\n",
    "                break\n",
    "\n",
    "    # Retrieve the latest frame\n",
    "    def read(self):\n",
    "        with self.lock:\n",
    "            ret, frame = self.cap.retrieve()\n",
    "        return ret, frame\n",
    "\n",
    "    def release(self):\n",
    "        self.running = False\n",
    "        self.t.join()\n",
    "        self.cap.release()\n",
    "\n",
    "\n",
    "cap = QVideoCapture(5)\n",
    "ret,frame = cap.read()\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "cap.release()\n",
    "\n",
    "# convert the i\n",
    "ax[0].imshow(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atexit\n",
    "import subprocess\n",
    "\n",
    "# Example: Starting a process\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    with open(\"tmp.log\", \"r\") as f:\n",
    "        f.write(\"hello\\n\")\n",
    "\n",
    "\n",
    "# Register the cleanup function\n",
    "atexit.register(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlexivPy.vision import RealSenseCamera\n",
    "import signal\n",
    "\n",
    "running = True\n",
    "\n",
    "\n",
    "\n",
    "# get an image. \n",
    "\n",
    "# Camera to the right of the robot\n",
    "# camera2 = RealSenseCamera(VGA=False, camera_serial_no='231622302407')\n",
    "\n",
    "# Camera to the left of the robot\n",
    "camera1 = RealSenseCamera(VGA=False, camera_serial_no='234222302193')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get an image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = camera1.color_frame\n",
    "# Assuming 'image' is your NumPy array image\n",
    "# Note: OpenCV uses width before height\n",
    "new_width = image.shape[1] // 10\n",
    "new_height = image.shape[0] // 10\n",
    "new_dimensions = (new_width, new_height)\n",
    "\n",
    "# Resize the image with INTER_AREA interpolation (best for shrinking)\n",
    "image_resized = cv2.resize(image, new_dimensions, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "# Extract the central 64x64 pixels\n",
    "height, width = image_resized.shape[:2]\n",
    "central_size = 64\n",
    "half_size = central_size // 2\n",
    "\n",
    "center_y = height // 2\n",
    "center_x = width // 2\n",
    "\n",
    "start_y = max(0, center_y - half_size)\n",
    "start_x = max(0, center_x - half_size)\n",
    "end_y = start_y + central_size\n",
    "end_x = start_x + central_size\n",
    "\n",
    "end_y = min(height, end_y)\n",
    "end_x = min(width, end_x)\n",
    "start_y = max(0, end_y - central_size)\n",
    "start_x = max(0, end_x - central_size)\n",
    "\n",
    "central_area = image_resized[start_y:end_y, start_x:end_x]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "print(camera1.color_frame.shape)\n",
    "# convert the i\n",
    "ax[0].imshow(camera1.color_frame)\n",
    "ax[1].imshow(image_resized)\n",
    "ax[2].imshow(central_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = []\n",
    "callback_dt = .1\n",
    "last_callback_t = -1\n",
    "\n",
    "cmds = []\n",
    "states = []\n",
    "imgs = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "runner = NonBlockingRunner(robot, task_controller, timeout=120. , callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets store the data.\n",
    "import pickle\n",
    "\n",
    "fout = \"tmp_data_v0.pkl\"\n",
    "\n",
    "with open(fout, \"wb\") as f:\n",
    "    pickle.dump({\"cmds\": cmds, \"states\": states, \"imgs\": imgs}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexivpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

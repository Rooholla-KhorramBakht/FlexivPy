{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CYCLONEDDS_URI\"] = \"file:///home/FlexivPy/cyclonedds_v0.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlexivPy.joy import XBoxController\n",
    "\n",
    "joy = XBoxController(0)\n",
    "joy.getStates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going through the next cells, start the asynchronous simulator or the real robot bridge by tunning the following in your terminal:\n",
    "\n",
    "**Asynchronous Simulator:**\n",
    "\n",
    "```bash\n",
    "flexivpy_async_sim --mode velocity\n",
    "```\n",
    "\n",
    "**Real Robot Client**\n",
    "\n",
    "```bash\n",
    "CYCLONEDDS_URI=file:///home/FlexivPy/cyclonedds_v0.xml robot_server -cm 3  --path /home/FlexivPy/FlexivPy/assets/ -rcf /home/FlexivPy/flexivpy_bridge/config.yaml\n",
    "```\n",
    "\n",
    "The `cm` 3 means that the robot is started in joint velocity mode.\n",
    "\n",
    "** Camera **\n",
    "```bash\n",
    "CYCLONEDDS_URI=file:///home/FlexivPy/cyclonedds_v0.xml python FlexivPy/async_camera_app.py\n",
    "\n",
    "CYCLONEDDS_URI=file:///home/FlexivPy/cyclonedds_v0.xml python FlexivPy/async_camera_app_multiple.py --camera_id 0 1 2\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinocchio as pin\n",
    "import numpy as np\n",
    "from FlexivPy.robot.model.pinocchio import FlexivModel\n",
    "from FlexivPy.robot.interface import FlexivDDSClient\n",
    "import time\n",
    "from FlexivPy.robot.dds.subscriber import get_last_msg\n",
    "import cv2\n",
    "from cyclonedds.domain import DomainParticipant\n",
    "from cyclonedds.topic import Topic\n",
    "from cyclonedds.sub import Subscriber, DataReader\n",
    "import time\n",
    "\n",
    "from cyclonedds.domain import DomainParticipant\n",
    "from cyclonedds.topic import Topic\n",
    "from FlexivPy.robot.dds.flexiv_messages import EnvImage\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from FlexivPy.camera_dds_client import CameraDDSClient\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "model = FlexivModel()\n",
    "robot = FlexivDDSClient()\n",
    "# Run this in another terminal!\n",
    "# python FlexivPy/async_camera_app.py\n",
    "\n",
    "camera1 = CameraDDSClient(camera_topic=\"EnvImage_0\")\n",
    "camera2 = CameraDDSClient(camera_topic=\"EnvImage_1\")\n",
    "camera3 = CameraDDSClient(camera_topic=\"EnvImage_2\")\n",
    "\n",
    "\n",
    "def cut_image(image, start_x, start_y, size):\n",
    "    end_y = start_y + size\n",
    "    end_x = start_x + size\n",
    "\n",
    "    interest_area = image[start_y:end_y, start_x:end_x]\n",
    "    if interest_area.shape[0] != size or interest_area.shape[1] != size:\n",
    "        raise ValueError(\n",
    "            \"Interest area is not the correct size. Expected size: {}, Actual size: {}\".format(\n",
    "                size, interest_area.shape\n",
    "            )\n",
    "        )\n",
    "    interest_area_6464 = cv2.resize(\n",
    "        interest_area, (64, 64), interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "    return interest_area_6464, interest_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = camera1.get_env_image()\n",
    "image2 = camera2.get_env_image()\n",
    "image3 = camera3.get_env_image()\n",
    "plt.rcParams[\"figure.dpi\"] = 400\n",
    "\n",
    "\n",
    "cut_image1 = partial(cut_image, start_x=75, start_y=90, size=135)\n",
    "cut_image2 = partial(cut_image, start_x=40, start_y=10, size=230)\n",
    "cut_image3 = partial(cut_image, start_x=50, start_y=20, size=220)\n",
    "\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "ax[0, 0].imshow(image1)\n",
    "ax[0, 1].imshow(image2)\n",
    "ax[0, 2].imshow(image3)\n",
    "\n",
    "# rigth camera.\n",
    "r_64, r_interest = cut_image1(image1)\n",
    "c_64, c_interest = cut_image2(image2)\n",
    "l_64, l_interest = cut_image3(image3)\n",
    "\n",
    "ax[1, 0].imshow(r_interest)\n",
    "ax[1, 1].imshow(c_interest)\n",
    "ax[1, 2].imshow(l_interest)\n",
    "\n",
    "# store the interest areas\n",
    "cv2.imwrite(\"r_interest.png\", cv2.cvtColor(r_interest, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(\"c_interest.png\", cv2.cvtColor(c_interest, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(\"l_interest.png\", cv2.cvtColor(l_interest, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "ax[2, 0].imshow(r_64)\n",
    "ax[2, 1].imshow(c_64)\n",
    "ax[2, 2].imshow(l_64)\n",
    "# tigth layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.imshow(np.concatenate((image1, get_small_image_center(image2), image3), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = camera1.get_env_image()\n",
    "image2 = camera2.get_env_image()\n",
    "image3 = camera3.get_env_image()\n",
    "\n",
    "r_64, r_interest = cut_image1(image1)\n",
    "c_64, c_interest = cut_image2(image2)\n",
    "l_64, l_interest = cut_image3(image3)\n",
    "\n",
    "\n",
    "# load the interest areas (old images)\n",
    "r_interest_old = cv2.imread(\"r_interest.png\")\n",
    "c_interest_old = cv2.imread(\"c_interest.png\")\n",
    "l_interest_old = cv2.imread(\"l_interest.png\")\n",
    "r_interest_old = cv2.cvtColor(r_interest_old, cv2.COLOR_BGR2RGB)\n",
    "c_interest_old = cv2.cvtColor(c_interest_old, cv2.COLOR_BGR2RGB)\n",
    "l_interest_old = cv2.cvtColor(l_interest_old, cv2.COLOR_BGR2RGB)\n",
    "# r_interest_old = cv2.cvtColor(r_interest_old, cv2.COLOR_BGR2RGB)\n",
    "# Make sure r_interest, c_interest, and l_interest are defined elsewhere\n",
    "# and contain the images you want to compare against the old ones.\n",
    "\n",
    "# # comare the interest areas\n",
    "# print(type(r_interest_old))\n",
    "# print(r_interest_old.dtype)\n",
    "# print(type(r_interest))\n",
    "# print(r_interest.dtype)\n",
    "diff_r = np.abs(r_interest_old / 255.0 - r_interest / 255.0) * 255\n",
    "diff_c = np.abs(c_interest_old / 255.0 - c_interest / 255.0) * 255\n",
    "diff_l = np.abs(l_interest_old / 255.0 - l_interest / 255.0) * 255\n",
    "\n",
    "print(\"max diff r: \", diff_r.max())\n",
    "print(\"max diff pixel r: \", diff_r.argmax())\n",
    "print(\"max diff c: \", diff_c.max())\n",
    "print(\"max diff l: \", diff_l.max())\n",
    "\n",
    "print(\"average diff r: \", diff_r.mean())\n",
    "print(\"average diff c: \", diff_c.mean())\n",
    "print(\"average diff l: \", diff_l.mean())\n",
    "\n",
    "# convert to uint8 for display\n",
    "diff_r = diff_r.astype(np.uint8)\n",
    "diff_c = diff_c.astype(np.uint8)\n",
    "diff_l = diff_l.astype(np.uint8)\n",
    "\n",
    "# clamp at 255 if necessary\n",
    "diff_r = np.clip(diff_r, 0, 255)\n",
    "diff_c = np.clip(diff_c, 0, 255)\n",
    "diff_l = np.clip(diff_l, 0, 255)\n",
    "\n",
    "fig, ax = plt.subplots(3, 3)\n",
    "ax[0, 0].imshow(r_interest_old)  # Convert BGR to RGB for display\n",
    "ax[0, 1].imshow(c_interest_old)\n",
    "ax[0, 2].imshow(l_interest_old)\n",
    "ax[1, 0].imshow(r_interest)\n",
    "ax[1, 1].imshow(c_interest)\n",
    "ax[1, 2].imshow(l_interest)\n",
    "ax[2, 0].imshow(diff_r)\n",
    "ax[2, 1].imshow(diff_c)\n",
    "ax[2, 2].imshow(diff_l)\n",
    "# average\n",
    "# ax[3, 0].imshow(np.mean([r_interest_old, r_interest], axis=0).astype(np.uint8))\n",
    "# ax[3, 1].imshow(np.mean([c_interest_old, c_interest], axis=0).astype(np.uint8))\n",
    "# ax[3, 2].imshow(np.mean([l_interest_old, l_interest], axis=0).astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure you have to enable x11 forwarding\n",
    "```bash\n",
    "xhost +\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "def resize_and_pad(image, max_width, max_height, color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Resizes and pads an image to fit within max_width and max_height while maintaining aspect ratio.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): The input image.\n",
    "        max_width (int): The maximum width.\n",
    "        max_height (int): The maximum height.\n",
    "        color (tuple): The padding color in BGR. Default is black.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The resized and padded image.\n",
    "    \"\"\"\n",
    "    original_height, original_width = image.shape[:2]\n",
    "\n",
    "    # Calculate scaling factor to fit the image within max dimensions\n",
    "    scale = min(max_width / original_width, max_height / original_height)\n",
    "    new_width = int(original_width * scale)\n",
    "    new_height = int(original_height * scale)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(\n",
    "        image, (new_width, new_height), interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "\n",
    "    # Calculate padding to center the image\n",
    "    delta_w = max_width - new_width\n",
    "    delta_h = max_height - new_height\n",
    "    top = delta_h // 2\n",
    "    bottom = delta_h - top\n",
    "    left = delta_w // 2\n",
    "    right = delta_w - left\n",
    "\n",
    "    # Apply padding\n",
    "    padded_image = cv2.copyMakeBorder(\n",
    "        resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color\n",
    "    )\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    image1 = camera1.get_env_image()\n",
    "    image2 = camera2.get_env_image()\n",
    "    image3 = camera3.get_env_image()\n",
    "\n",
    "    img_raw = np.concatenate((image1, image2, image3), axis=1)\n",
    "    r_64, r_interest = cut_image1(image1)\n",
    "    c_64, c_interest = cut_image2(image2)\n",
    "    l_64, l_interest = cut_image3(image3)\n",
    "\n",
    "    r_interest = cv2.resize(r_interest, (64 * 2, 64 * 2), interpolation=cv2.INTER_AREA)\n",
    "    c_interest = cv2.resize(c_interest, (64 * 2, 64 * 2), interpolation=cv2.INTER_AREA)\n",
    "    l_interest = cv2.resize(l_interest, (64 * 2, 64 * 2), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    img_interest = np.concatenate((r_interest, c_interest, l_interest), axis=1)\n",
    "    img_64 = np.concatenate((r_64, c_64, l_64), axis=1)\n",
    "\n",
    "    img_interest = resize_and_pad(img_interest, img_raw.shape[1], img_raw.shape[0])\n",
    "    img_64 = resize_and_pad(img_64, img_raw.shape[1], img_raw.shape[0])\n",
    "\n",
    "    img_all = np.concatenate((img_raw, img_interest, img_64), axis=0)\n",
    "\n",
    "    cv2.imshow(\"images\", img_all)\n",
    "    cv2.waitKey(1)\n",
    "    time.sleep(0.1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlexivPy.controllers.jointspace import GoJointConfigurationVelocity\n",
    "from FlexivPy.controllers.runners import blocking_runner\n",
    "\n",
    "state = robot.get_robot_state()\n",
    "info = model.getInfo(np.array(state.q), np.array(state.dq))\n",
    "print(info[\"poses\"][\"link7\"])\n",
    "print(state.q)\n",
    "\n",
    "\n",
    "# homing_controller = GoJointConfigurationVelocity(qgoal=np.array([-0.060038141906261444, -0.1400885432958603, 0.11492829769849777, 2.026796817779541, 0.0031041193287819624, 0.5770605802536011, 0.]))\n",
    "# blocking_runner(robot, homing_controller)\n",
    "\n",
    "# default T is :\n",
    "\n",
    "target_t = np.array(\n",
    "    [\n",
    "        [1, 0, 0, 0.48986543],\n",
    "        [0, -1, 0, -0.08922464],\n",
    "        [0, 0, -1, 0.65726634],\n",
    "        [0.0, 0.0, 0.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "q0 = np.array(\n",
    "    [\n",
    "        -0.006483817007392645,\n",
    "        -0.2647894322872162,\n",
    "        0.1409081667661667,\n",
    "        1.9820226430892944,\n",
    "        -0.04699726402759552,\n",
    "        0.6730022430419922,\n",
    "        0.1588847041130066,\n",
    "    ]\n",
    ")\n",
    "\n",
    "pre_q0 = np.array(\n",
    "    [\n",
    "        -0.060038141906261444,\n",
    "        -0.1400885432958603,\n",
    "        0.11492829769849777,\n",
    "        2.026796817779541,\n",
    "        0.0031041193287819624,\n",
    "        0.5770605802536011,\n",
    "        0.0,\n",
    "    ]\n",
    ")\n",
    "\n",
    "blocking_runner(robot, GoJointConfigurationVelocity(qgoal=pre_q0, max_v=0.05))\n",
    "blocking_runner(robot, GoJointConfigurationVelocity(qgoal=q0, max_v=0.05))\n",
    "\n",
    "state = robot.get_robot_state()\n",
    "info = model.getInfo(np.array(state.q), np.array(state.dq))\n",
    "\n",
    "T0_ref = np.array(\n",
    "    [\n",
    "        [1.00000000e00, -2.69497544e-06, 2.74733386e-05, 5.31326556e-01],\n",
    "        [-2.69558521e-06, -1.00000000e00, 2.21951225e-05, -4.72725715e-02],\n",
    "        [2.74732787e-05, -2.21951966e-05, -9.99999999e-01, 6.27520138e-01],\n",
    "        [0.00000000e00, 0.00000000e00, 0.00000000e00, 1.00000000e00],\n",
    "    ]\n",
    ")\n",
    "\n",
    "if np.linalg.norm(T0_ref - info[\"poses\"][\"link7\"]) > 1e-2:\n",
    "    print(\n",
    "        \"error in the robot position\", np.linalg.norm(T0_ref - info[\"poses\"][\"link7\"])\n",
    "    )\n",
    "    print(\"The robot is not at the correct position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlexivPy.controllers.taskspace import (\n",
    "    DiffIKController,\n",
    "    Get_T_from_controller_no_drift,\n",
    ")\n",
    "import imageio\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from zoneinfo import ZoneInfo\n",
    "from FlexivPy.controllers.runners import blocking_runner\n",
    "\n",
    "\n",
    "# state = robot.get_robot_state()\n",
    "# info = model.getInfo(np.array(state.q), np.array(state.dq))\n",
    "# T0_ref = info[\"poses\"][\"link7\"]\n",
    "\n",
    "\n",
    "get_T_from_controller_no_drift = Get_T_from_controller_no_drift(\n",
    "    T0=T0_ref, joy=joy, max_v=0.35\n",
    ")\n",
    "\n",
    "task_controller = DiffIKController(\n",
    "    model,\n",
    "    T_cmd_fun=get_T_from_controller_no_drift,\n",
    "    dt=0.01,\n",
    "    dq_max=1.0,\n",
    "    control_mode=\"velocity\",\n",
    ")\n",
    "\n",
    "\n",
    "def save_image_pil(im, fout):\n",
    "    # A helper function to save the image\n",
    "    im.save(fout)\n",
    "\n",
    "\n",
    "class CallbackFun:\n",
    "    def __init__(self, base_folder_name, max_workers_pool=1):\n",
    "        self.cmds = []\n",
    "        self.callback_dt = 0.1\n",
    "        self.states = []\n",
    "        self.img_names = []\n",
    "        self.raw_img_names = []\n",
    "        self.last_callback_t = -1\n",
    "        self.img_counter = 0\n",
    "\n",
    "        self.img_dir = base_folder_name / \"img/\"\n",
    "        self.img_raw_dir = base_folder_name / \"img_raw/\"\n",
    "        self.data_dir = base_folder_name / \"data/\"\n",
    "\n",
    "        (self.img_dir / \"cam1\").mkdir(parents=True, exist_ok=True)\n",
    "        (self.img_dir / \"cam2\").mkdir(parents=True, exist_ok=True)\n",
    "        (self.img_dir / \"cam3\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        (self.img_raw_dir / \"cam1\").mkdir(parents=True, exist_ok=True)\n",
    "        (self.img_raw_dir / \"cam2\").mkdir(parents=True, exist_ok=True)\n",
    "        (self.img_raw_dir / \"cam3\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Create a thread pool executor for asynchronous saving\n",
    "        self.executor = ThreadPoolExecutor(max_workers=max_workers_pool)\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" \"\"\"\n",
    "\n",
    "        Dataout = {\n",
    "            \"q\": [[i for i in x.q] for x in callback.states],\n",
    "            \"dq\": [[i for i in x.dq] for x in callback.states],\n",
    "            \"imgs\": callback.img_names,\n",
    "            \"raw_imgs\": callback.raw_img_names,\n",
    "        }\n",
    "\n",
    "        with open(self.data_dir / \"data.pkl\", \"wb\") as f:\n",
    "            pickle.dump(Dataout, f)\n",
    "\n",
    "        with open(self.data_dir / \"data.json\", \"w\") as f:\n",
    "            json.dump(Dataout, f)\n",
    "\n",
    "        # generate a video in mp4 format.\n",
    "        for cam_name in [\"cam1\", \"cam2\", \"cam3\"]:\n",
    "            images = []\n",
    "            for img in self.img_names:\n",
    "                images.append(imageio.imread(img[cam_name]))\n",
    "            imageio.mimsave(\n",
    "                self.img_dir / cam_name / f\"vid_{cam_name}.mp4\",\n",
    "                images,\n",
    "                fps=1.0 / self.callback_dt,\n",
    "                codec=\"h264\",\n",
    "            )\n",
    "            images_raw = []\n",
    "            for img in self.raw_img_names:\n",
    "                images_raw.append(imageio.imread(img[cam_name]))\n",
    "            imageio.mimsave(\n",
    "                self.img_raw_dir / cam_name / f\"vid_raw_{cam_name}.mp4\",\n",
    "                images_raw,\n",
    "                fps=1.0 / self.callback_dt,\n",
    "                codec=\"h264\",\n",
    "            )\n",
    "\n",
    "    def __call__(self, robot, cmd, _):\n",
    "        tic = time.time()\n",
    "        if tic - self.last_callback_t > self.callback_dt:\n",
    "            self.last_callback_t = tic\n",
    "\n",
    "            fcam1 = self.img_dir / \"cam1\" / f\"cam1_{self.img_counter:09d}.png\"\n",
    "            fcam2 = self.img_dir / \"cam2\" / f\"cam2_{self.img_counter:09d}.png\"\n",
    "            fcam3 = self.img_dir / \"cam3\" / f\"cam3_{self.img_counter:09d}.png\"\n",
    "\n",
    "            fcam1_big = (\n",
    "                self.img_raw_dir / \"cam1\" / f\"cam1_raw_{self.img_counter:09d}.jpg\"\n",
    "            )\n",
    "            fcam2_big = (\n",
    "                self.img_raw_dir / \"cam2\" / f\"cam2_raw_{self.img_counter:09d}.jpg\"\n",
    "            )\n",
    "            fcam3_big = (\n",
    "                self.img_raw_dir / \"cam3\" / f\"cam3_raw_{self.img_counter:09d}.jpg\"\n",
    "            )\n",
    "\n",
    "            self.img_names.append(\n",
    "                {\"cam1\": str(fcam1), \"cam2\": str(fcam2), \"cam3\": str(fcam3)}\n",
    "            )\n",
    "            self.raw_img_names.append(\n",
    "                {\n",
    "                    \"cam1\": str(fcam1_big),\n",
    "                    \"cam2\": str(fcam2_big),\n",
    "                    \"cam3\": str(fcam3_big),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            self.cmds.append(cmd)\n",
    "            self.states.append(robot.get_robot_state())\n",
    "\n",
    "            # store the image as png.\n",
    "            img1 = camera1.get_env_image()\n",
    "            img2 = camera2.get_env_image()\n",
    "            img3 = camera3.get_env_image()\n",
    "\n",
    "            img1_64, _ = cut_image1(img1)\n",
    "            img2_64, _ = cut_image2(img2)\n",
    "            img3_64, _ = cut_image3(img3)\n",
    "\n",
    "            self.executor.submit(save_image_pil, Image.fromarray(img1_64), fcam1)\n",
    "            self.executor.submit(save_image_pil, Image.fromarray(img2_64), fcam2)\n",
    "            self.executor.submit(save_image_pil, Image.fromarray(img3_64), fcam3)\n",
    "\n",
    "            self.executor.submit(\n",
    "                save_image_pil,\n",
    "                Image.fromarray(img1),\n",
    "                fcam1_big,\n",
    "            )\n",
    "            self.executor.submit(\n",
    "                save_image_pil,\n",
    "                Image.fromarray(img2),\n",
    "                fcam2_big,\n",
    "            )\n",
    "            self.executor.submit(\n",
    "                save_image_pil,\n",
    "                Image.fromarray(img3),\n",
    "                fcam3_big,\n",
    "            )\n",
    "\n",
    "            if self.executor._work_queue.qsize() > 100:\n",
    "                print(\n",
    "                    \"pool to save img to disk queue is big\",\n",
    "                    self.executor._work_queue.qsize(),\n",
    "                )\n",
    "\n",
    "            self.img_counter += 1\n",
    "\n",
    "\n",
    "# Get local time zone (replace with your desired time zone if needed)\n",
    "local_timezone = ZoneInfo(\"America/New_York\")  # Replace with your timezone\n",
    "\n",
    "# Get current date and time\n",
    "current_datetime = datetime.now(local_timezone)\n",
    "\n",
    "# Format the datetime string for folder name\n",
    "folder_name = current_datetime.strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "base_folder_name = pathlib.Path(\"data_t_v1\") / folder_name\n",
    "\n",
    "callback = CallbackFun(base_folder_name=base_folder_name, max_workers_pool=1)\n",
    "\n",
    "status = blocking_runner(robot, task_controller, timeout=60, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to disk (image names and robot states)\n",
    "callback.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexivpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
